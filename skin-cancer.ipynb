{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":505351,"sourceType":"datasetVersion","datasetId":174469}],"dockerImageVersionId":30513,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/ghazalehalizade/skin-cancer?scriptVersionId=247872871\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# Import needed modules","metadata":{"id":"CKeVGxZ5GG6o"}},{"cell_type":"code","source":"train_data_dir = '/kaggle/input/skin-cancer-malignant-vs-benign/train'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-28T17:47:42.917193Z","iopub.execute_input":"2025-06-28T17:47:42.91753Z","iopub.status.idle":"2025-06-28T17:47:42.929222Z","shell.execute_reply.started":"2025-06-28T17:47:42.917487Z","shell.execute_reply":"2025-06-28T17:47:42.928112Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"âœ… Confirm the Dataset Path","metadata":{}},{"cell_type":"code","source":"# import system libs\nimport os\nimport time\nimport shutil\nimport pathlib\nimport itertools\nfrom PIL import Image\n\n# import data handling tools\nimport cv2\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nsns.set_style('darkgrid')\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, classification_report\n\n# import Deep learning Libraries\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.optimizers import Adam, Adamax\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Activation, Dropout, BatchNormalization\nfrom tensorflow.keras import regularizers\n\n# Ignore Warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nprint ('modules loaded')","metadata":{"id":"CeMcAy_5GG6s","outputId":"8e007371-6c2c-492c-99bb-172286922ae2","execution":{"iopub.status.busy":"2025-06-28T17:47:50.689703Z","iopub.execute_input":"2025-06-28T17:47:50.690042Z","iopub.status.idle":"2025-06-28T17:47:59.632504Z","shell.execute_reply.started":"2025-06-28T17:47:50.690016Z","shell.execute_reply":"2025-06-28T17:47:59.631608Z"},"trusted":true},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"},{"name":"stdout","text":"modules loaded\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import tensorflow as tf\n\nprint(\"TensorFlow version:\", tf.__version__)","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2025-06-28T17:48:05.533959Z","iopub.execute_input":"2025-06-28T17:48:05.534979Z","iopub.status.idle":"2025-06-28T17:48:05.539392Z","shell.execute_reply.started":"2025-06-28T17:48:05.534951Z","shell.execute_reply":"2025-06-28T17:48:05.538465Z"},"trusted":true},"outputs":[{"name":"stdout","text":"TensorFlow version: 2.12.0\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"# **Data Preprocessing**","metadata":{"id":"SA_gwvwnGG6v"}},{"cell_type":"markdown","source":"### **Read data and store it in dataframe**","metadata":{"id":"e4reLHLHabWD"}},{"cell_type":"markdown","source":"**ðŸ§  Goal:**\nTo convert the folder structure of images (e.g., train/benign/*.jpg, train/malignant/*.jpg) into a pandas DataFrame like this:\n\n| filepaths                         | labels    |\n| --------------------------------- | --------- |\n| /kaggle/input/.../benign/1.jpg    | benign    |\n| /kaggle/input/.../malignant/2.jpg | malignant |\n","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# Split into train and test (or validation)\ntrain_df, test_df = train_test_split(\n    train_df,\n    test_size=0.2,  # 20% test, adjust as needed\n    stratify=train_df['labels'],\n    random_state=42\n)\n\n# Reset index (optional, but helps with reproducibility)\ntrain_df = train_df.reset_index(drop=True)\ntest_df = test_df.reset_index(drop=True)\n\nprint('Training samples:', len(train_df))\nprint('Testing samples:', len(test_df))\n","metadata":{"execution":{"iopub.status.busy":"2025-06-27T08:42:11.108803Z","iopub.execute_input":"2025-06-27T08:42:11.10955Z","iopub.status.idle":"2025-06-27T08:42:11.120828Z","shell.execute_reply.started":"2025-06-27T08:42:11.109518Z","shell.execute_reply":"2025-06-27T08:42:11.119954Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(train_df.head())\nprint(train_df['labels'].value_counts())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-27T08:34:03.200692Z","iopub.execute_input":"2025-06-27T08:34:03.201241Z","iopub.status.idle":"2025-06-27T08:34:03.21141Z","shell.execute_reply.started":"2025-06-27T08:34:03.201215Z","shell.execute_reply":"2025-06-27T08:34:03.210498Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(os.listdir('/kaggle/input/skin-cancer-malignant-vs-benign'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-27T08:33:29.932878Z","iopub.execute_input":"2025-06-27T08:33:29.933161Z","iopub.status.idle":"2025-06-27T08:33:29.94188Z","shell.execute_reply.started":"2025-06-27T08:33:29.93314Z","shell.execute_reply":"2025-06-27T08:33:29.941138Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### **Create image data generator**","metadata":{}},{"cell_type":"code","source":"batch_size = 16\nimg_size = (224, 224)\nchannels = 3\n\ntr_gen = ImageDataGenerator(\n    rotation_range=20,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    zoom_range=0.15,\n    horizontal_flip=True,\n    vertical_flip=True,\n    fill_mode='nearest'\n)\n\n\nts_gen = ImageDataGenerator()\n\ntrain_gen = tr_gen.flow_from_dataframe(\n    train_df, x_col='filepaths', y_col='labels',\n    target_size=img_size, class_mode='categorical',\n    color_mode='rgb', shuffle=True, batch_size=batch_size\n)\n\ntest_gen = ts_gen.flow_from_dataframe(\n    test_df, x_col='filepaths', y_col='labels',\n    target_size=img_size, class_mode='categorical',\n    color_mode='rgb', shuffle=False, batch_size=batch_size\n)","metadata":{"execution":{"iopub.status.busy":"2025-06-27T09:44:19.734496Z","iopub.execute_input":"2025-06-27T09:44:19.735245Z","iopub.status.idle":"2025-06-27T09:44:19.772525Z","shell.execute_reply.started":"2025-06-27T09:44:19.735217Z","shell.execute_reply":"2025-06-27T09:44:19.771719Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### **Show sample from train data**","metadata":{}},{"cell_type":"code","source":"g_dict = train_gen.class_indices      # defines dictionary {'class': index}\nclasses = list(g_dict.keys())       # defines list of dictionary's kays (classes), classes names : string\nimages, labels = next(train_gen)      # get a batch size samples from the generator\n\nplt.figure(figsize= (20, 20))\n\nfor i in range(16):\n    plt.subplot(4, 4, i + 1)\n    image = images[i] / 255       # scales data to range (0 - 255)\n    plt.imshow(image)\n    index = np.argmax(labels[i])  # get image index\n    class_name = classes[index]   # get class of image\n    plt.title(class_name, color= 'blue', fontsize= 12)\n    plt.axis('off')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2025-06-27T08:44:08.518785Z","iopub.execute_input":"2025-06-27T08:44:08.519105Z","iopub.status.idle":"2025-06-27T08:44:12.220691Z","shell.execute_reply.started":"2025-06-27T08:44:08.519083Z","shell.execute_reply":"2025-06-27T08:44:12.219321Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Model Structure**","metadata":{"id":"57eDFl3oGG65"}},{"cell_type":"markdown","source":"#### **Generic Model Creation**","metadata":{"id":"3wvOKjeRGG65"}},{"cell_type":"code","source":"# Create Model Structure\nimg_size = (224, 224)\nchannels = 3\nimg_shape = (img_size[0], img_size[1], channels)\nclass_count = len(list(train_gen.class_indices.keys())) # to define number of classes in dense layer\n\n\n# create pre-trained model (you can built on pretrained model such as :  efficientnet, VGG , Resnet )\n# we will use efficientnetb3 from EfficientNet family.\nbase_model = tf.keras.applications.efficientnet.EfficientNetB0(\n    include_top=False, weights=\"imagenet\", input_shape=img_shape, pooling='max'\n)\nbase_model.trainable = False  # Freeze base model\n\nmodel = Sequential([\n    base_model,\n    BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001),\n    Dense(256, kernel_regularizer=regularizers.l2(0.02), activity_regularizer=regularizers.l1(0.01),\n          bias_regularizer=regularizers.l1(0.01), activation='relu'),\n    Dropout(rate=0.5, seed=123),\n    Dense(class_count, activation='softmax')\n])\nmodel.compile(Adamax(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n\nmodel.summary()\n","metadata":{"id":"kDT4CV15abWT","outputId":"365637a8-7535-4ac4-90ea-700f6eb5769e","trusted":true,"execution":{"iopub.status.busy":"2025-06-27T09:44:29.568734Z","iopub.execute_input":"2025-06-27T09:44:29.569414Z","iopub.status.idle":"2025-06-27T09:44:31.937262Z","shell.execute_reply.started":"2025-06-27T09:44:29.569383Z","shell.execute_reply":"2025-06-27T09:44:31.936415Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"| Layer                 | Output Shape | Param #   | Purpose                |\n| --------------------- | ------------ | --------- | ---------------------- |\n| `efficientnetb0`      | (None, 1280) | 4,049,571 | Pretrained base        |\n| `batch_normalization` | (None, 1280) | 5,120     | Normalize output       |\n| `dense`               | (None, 256)  | 327,936   | First classifier layer |\n| `dropout`             | (None, 256)  | 0         | Prevent overfitting    |\n| `dense_1`             | (None, 2)    | 514       | Final softmax layer    |\n","metadata":{}},{"cell_type":"code","source":"history = model.fit(\n    train_gen,\n    epochs=5,  # just a few epochs\n    validation_data=test_gen,\n    callbacks=[early_stop, checkpoint, reduce_lr]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-27T09:44:37.230311Z","iopub.execute_input":"2025-06-27T09:44:37.231128Z","iopub.status.idle":"2025-06-27T09:46:49.155198Z","shell.execute_reply.started":"2025-06-27T09:44:37.231095Z","shell.execute_reply":"2025-06-27T09:46:49.154309Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### **Train model**","metadata":{"id":"ap89fjdxGG67"}},{"cell_type":"code","source":"from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n\n# Optional: define callbacks\nearly_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\ncheckpoint = ModelCheckpoint('best_model.h5', monitor='val_loss', save_best_only=True, save_weights_only=True)\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-6)\n\n# Train the model\nhistory = model.fit(\n    train_gen,\n    epochs=20,  # adjust as needed\n    validation_data=test_gen,\n    callbacks=[early_stop, checkpoint, reduce_lr]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-27T09:41:24.351308Z","iopub.execute_input":"2025-06-27T09:41:24.352059Z","iopub.status.idle":"2025-06-27T09:43:49.605803Z","shell.execute_reply.started":"2025-06-27T09:41:24.352029Z","shell.execute_reply":"2025-06-27T09:43:49.60492Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### **Display model performance**","metadata":{"id":"dNKq6ebOGG67"}},{"cell_type":"code","source":"# Define needed variables\ntr_acc = history.history['accuracy']\ntr_loss = history.history['loss']\nval_acc = history.history['val_accuracy']\nval_loss = history.history['val_loss']\nindex_loss = np.argmin(val_loss)\nval_lowest = val_loss[index_loss]\nindex_acc = np.argmax(val_acc)\nacc_highest = val_acc[index_acc]\nEpochs = [i+1 for i in range(len(tr_acc))]\nloss_label = f'best epoch= {str(index_loss + 1)}'\nacc_label = f'best epoch= {str(index_acc + 1)}'\n\n# Plot training history\nplt.figure(figsize= (20, 8))\nplt.style.use('fivethirtyeight')\n\nplt.subplot(1, 2, 1)\nplt.plot(Epochs, tr_loss, 'r', label= 'Training loss')\nplt.plot(Epochs, val_loss, 'g', label= 'Validation loss')\nplt.scatter(index_loss + 1, val_lowest, s= 150, c= 'blue', label= loss_label)\nplt.title('Training and Validation Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.subplot(1, 2, 2)\nplt.plot(Epochs, tr_acc, 'r', label= 'Training Accuracy')\nplt.plot(Epochs, val_acc, 'g', label= 'Validation Accuracy')\nplt.scatter(index_acc + 1 , acc_highest, s= 150, c= 'blue', label= acc_label)\nplt.title('Training and Validation Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\n\nplt.tight_layout\nplt.show()","metadata":{"id":"L0Bj0Sp_GG68","outputId":"663963ec-ea21-4272-8dda-a16c5f5e2ce5","execution":{"iopub.status.busy":"2025-06-27T09:23:56.179558Z","iopub.execute_input":"2025-06-27T09:23:56.179855Z","iopub.status.idle":"2025-06-27T09:23:56.8847Z","shell.execute_reply.started":"2025-06-27T09:23:56.179833Z","shell.execute_reply":"2025-06-27T09:23:56.883799Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Evaluate model**","metadata":{"id":"MySXhfAJGG68"}},{"cell_type":"code","source":"ts_length = len(test_df)\ntest_batch_size = max(sorted([ts_length // n for n in range(1, ts_length + 1) if ts_length%n == 0 and ts_length/n <= 80]))\ntest_steps = ts_length // test_batch_size\n\ntrain_score = model.evaluate(train_gen, steps= test_steps, verbose= 1)\ntest_score = model.evaluate(test_gen, steps= test_steps, verbose= 1)\n\nprint(\"Train Loss: \", train_score[0])\nprint(\"Train Accuracy: \", train_score[1])\nprint('-' * 20)\nprint(\"Test Loss: \", test_score[0])\nprint(\"Test Accuracy: \", test_score[1])","metadata":{"id":"wSKDkyXXGG68","outputId":"b521980b-a33b-421b-8cdf-4d92fb0f304a","execution":{"iopub.status.busy":"2025-06-23T15:04:25.755338Z","iopub.execute_input":"2025-06-23T15:04:25.75603Z","iopub.status.idle":"2025-06-23T15:04:26.925677Z","shell.execute_reply.started":"2025-06-23T15:04:25.756001Z","shell.execute_reply":"2025-06-23T15:04:26.924648Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Get Predictions**","metadata":{"id":"4l-DABtFGG68"}},{"cell_type":"code","source":"preds = model.predict_generator(test_gen)\ny_pred = np.argmax(preds, axis=1)","metadata":{"id":"GDFj7MZdGG69","outputId":"6dbce8ed-fc8c-4398-b8bd-1ce8cb403727","execution":{"iopub.status.busy":"2025-06-23T15:04:36.900015Z","iopub.execute_input":"2025-06-23T15:04:36.90084Z","iopub.status.idle":"2025-06-23T15:04:40.043555Z","shell.execute_reply.started":"2025-06-23T15:04:36.900809Z","shell.execute_reply":"2025-06-23T15:04:40.042604Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### **Confusion Matrics and Classification Report**","metadata":{"id":"aJscUTF6GG69"}},{"cell_type":"code","source":"g_dict = test_gen.class_indices\nclasses = list(g_dict.keys())\n\n# Confusion matrix\ncm = confusion_matrix(test_gen.classes, y_pred)\n\nplt.figure(figsize= (10, 10))\nplt.imshow(cm, interpolation= 'nearest', cmap= plt.cm.Blues)\nplt.title('Confusion Matrix')\nplt.colorbar()\n\ntick_marks = np.arange(len(classes))\nplt.xticks(tick_marks, classes, rotation= 45)\nplt.yticks(tick_marks, classes)\n\n\nthresh = cm.max() / 2.\nfor i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n    plt.text(j, i, cm[i, j], horizontalalignment= 'center', color= 'white' if cm[i, j] > thresh else 'black')\n\nplt.tight_layout()\nplt.ylabel('True Label')\nplt.xlabel('Predicted Label')\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2025-06-23T15:04:44.402696Z","iopub.execute_input":"2025-06-23T15:04:44.403484Z","iopub.status.idle":"2025-06-23T15:04:44.773436Z","shell.execute_reply.started":"2025-06-23T15:04:44.403453Z","shell.execute_reply":"2025-06-23T15:04:44.772522Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Classification report\nprint(classification_report(test_gen.classes, y_pred, target_names= classes))","metadata":{"id":"tQR-UlD6GG69","outputId":"09ac1d97-2053-4633-e066-ca11540a2e27","execution":{"iopub.status.busy":"2025-06-23T15:05:17.342166Z","iopub.execute_input":"2025-06-23T15:05:17.343012Z","iopub.status.idle":"2025-06-23T15:05:17.35558Z","shell.execute_reply.started":"2025-06-23T15:05:17.342975Z","shell.execute_reply":"2025-06-23T15:05:17.354613Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### **Save model**","metadata":{"id":"SsIK5v0lGG69"}},{"cell_type":"code","source":"import os\nos.listdir()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-23T15:05:21.120618Z","iopub.execute_input":"2025-06-23T15:05:21.121373Z","iopub.status.idle":"2025-06-23T15:05:21.126925Z","shell.execute_reply.started":"2025-06-23T15:05:21.121342Z","shell.execute_reply":"2025-06-23T15:05:21.126121Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.save(\"skincancer.h5\")","metadata":{"id":"UiHQzq8XGG6-","outputId":"e2daeab5-c65c-495c-ffde-be259c917c07","execution":{"iopub.status.busy":"2025-06-23T15:46:23.647021Z","iopub.execute_input":"2025-06-23T15:46:23.647864Z","iopub.status.idle":"2025-06-23T15:46:23.7676Z","shell.execute_reply.started":"2025-06-23T15:46:23.647832Z","shell.execute_reply":"2025-06-23T15:46:23.766332Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"loaded_model = tf.keras.models.load_model('/kaggle/working/skincancer.h5', compile=False)\nloaded_model.compile(Adamax(learning_rate= 0.001), loss= 'categorical_crossentropy', metrics= ['accuracy'])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-23T15:46:41.299807Z","iopub.execute_input":"2025-06-23T15:46:41.300456Z","iopub.status.idle":"2025-06-23T15:46:41.3529Z","shell.execute_reply.started":"2025-06-23T15:46:41.300427Z","shell.execute_reply":"2025-06-23T15:46:41.351781Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **Prediction using loaded_model**","metadata":{}},{"cell_type":"code","source":"loaded_model = tf.keras.models.load_model('/kaggle/working/skincancer.h5', compile=False)\nloaded_model.compile(Adamax(learning_rate= 0.001), loss= 'categorical_crossentropy', metrics= ['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2025-06-23T15:46:56.150375Z","iopub.execute_input":"2025-06-23T15:46:56.151084Z","iopub.status.idle":"2025-06-23T15:46:56.202307Z","shell.execute_reply.started":"2025-06-23T15:46:56.151036Z","shell.execute_reply":"2025-06-23T15:46:56.201142Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"image_path = '/kaggle/input/skin-cancer-malignant-vs-benign/test/benign/1023.jpg'\nimage = Image.open(image_path)\n# Preprocess the image\nimg = image.resize((224, 224))\nimg_array = tf.keras.preprocessing.image.img_to_array(img)\nimg_array = tf.expand_dims(img_array, 0)\n# Make predictions\npredictions = loaded_model.predict(img_array)\nclass_labels = ['Benign', 'Malignant']\nscore = tf.nn.softmax(predictions[0])\nprint(f\"{class_labels[tf.argmax(score)]}\")","metadata":{"execution":{"iopub.status.busy":"2025-06-23T15:06:55.353659Z","iopub.execute_input":"2025-06-23T15:06:55.354367Z","iopub.status.idle":"2025-06-23T15:06:55.39443Z","shell.execute_reply.started":"2025-06-23T15:06:55.354334Z","shell.execute_reply":"2025-06-23T15:06:55.393458Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Convert to tflite","metadata":{}},{"cell_type":"code","source":"converter = tf.lite.TFLiteConverter.from_keras_model(model) \ntflite_model = converter.convert() \n\nprint(\"model converted\")\n\n# Save the model. \nwith open('Brain.tflite', 'wb') as f:\n    f.write(tflite_model)","metadata":{"execution":{"iopub.status.busy":"2025-06-23T15:07:01.93468Z","iopub.execute_input":"2025-06-23T15:07:01.935538Z","iopub.status.idle":"2025-06-23T15:08:14.854835Z","shell.execute_reply.started":"2025-06-23T15:07:01.935505Z","shell.execute_reply":"2025-06-23T15:08:14.853997Z"},"trusted":true},"outputs":[],"execution_count":null}]}